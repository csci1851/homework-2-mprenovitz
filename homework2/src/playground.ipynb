{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 Playground\n",
    "\n",
    "Fill in TODOs as you work through the assignment.\n",
    "Implement the required sections in `model.py`, and use this notebook to orchestrate and run your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from hw2_loader import HW2DataLoader\n",
    "from model import GradientBoostingModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded heart disease data with 1025 rows\n",
      "(1025, 13) {1: 526, 0: 499}\n",
      "(801, 5479) {'BRCA': 300, 'KIRC': 146, 'LUAD': 141, 'PRAD': 136, 'COAD': 78}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load both datasets\n",
    "loader = HW2DataLoader()\n",
    "\n",
    "# Heart disease dataset\n",
    "heart_path = Path('../data/heart.csv')\n",
    "X_heart, y_heart = loader.get_heart_disease_data(csv_path=heart_path)\n",
    "print(X_heart.shape, y_heart.value_counts().to_dict())\n",
    "\n",
    "# Cancer genomics dataset\n",
    "cancer_path = Path('../data/cancer_genomics.csv')\n",
    "labels_path = Path('../data/labels_cancer_genomics.csv')\n",
    "X_cancer, y_cancer = loader.get_cancer_genomics_data(\n",
    "    csv_path=cancer_path, labels_path=labels_path\n",
    ")\n",
    "print(X_cancer.shape, y_cancer.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize your model (adjust params)\n",
    "model = GradientBoostingModel(\n",
    "    task='classification',\n",
    "    max_depth= 3,\n",
    "    learning_rate= 0.1,\n",
    "    n_estimators= 50,\n",
    "    subsample= 1,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    random_state=42,\n",
    "    use_scaler=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dedup X: 723\n",
      "Before dedup y: 1023\n",
      "After dedup X: 0\n",
      "After dedup y: 300\n",
      "Check for NA \n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<model.GradientBoostingModel at 0x13da893d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train/test split + fit (heart)\n",
    "print('Before dedup X:', X_heart.duplicated().sum())\n",
    "print('Before dedup y:', y_heart.duplicated().sum())\n",
    "#TODO ask about deduplicating \n",
    "duplicated = X_heart.duplicated()\n",
    "X_heart = X_heart[~duplicated]\n",
    "y_heart = y_heart[~duplicated]\n",
    "print('After dedup X:', X_heart.duplicated().sum())\n",
    "print('After dedup y:', y_heart.duplicated().sum())\n",
    "\n",
    "\n",
    "print('Check for NA \\n', X_heart.isna().sum())\n",
    "X_train, X_test, y_train, y_test = model.train_test_split(X_heart, y_heart, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7868852459016393, 'precision': 0.7352941176470589, 'recall': 0.8620689655172413, 'f1': 0.7936507936507936, 'roc_auc': 0.8459051724137931}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate (heart)\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'mean': np.float64(0.8110928961748634), 'std': np.float64(0.05683811425746767)}, 'precision': {'mean': np.float64(0.8044289044289045), 'std': np.float64(0.05482653147641297)}, 'recall': {'mean': np.float64(0.866098484848485), 'std': np.float64(0.05238925308098828)}, 'f1': {'mean': np.float64(0.8334242086415999), 'std': np.float64(0.04755082348585735)}, 'roc_auc': {'mean': np.float64(0.892242364117364), 'std': np.float64(0.044243684238676334)}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Cross-validation (heart)\n",
    "cv_results = model.cross_validate(X_heart, y_heart)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Importance\n",
      "cp          0.271179\n",
      "thal        0.152293\n",
      "oldpeak     0.132348\n",
      "ca          0.103459\n",
      "age         0.072785\n",
      "thalach     0.065468\n",
      "trestbps    0.055822\n",
      "chol        0.053773\n",
      "sex         0.038690\n",
      "slope       0.023003\n"
     ]
    }
   ],
   "source": [
    "# TODO: Feature importance (heart)\n",
    "feature_importance = model.get_feature_importance(plot=False)\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 15, 'min_samples_leaf': 6, 'min_samples_split': 6, 'n_estimators': 50, 'subsample': 0.25}\n",
      "0.9178865954228272\n"
     ]
    }
   ],
   "source": [
    "# TODO: Hyperparameter tuning (heart)\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, 15, 20, 25],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.05, 0.07, 0.1],\n",
    "    \"n_estimators\": [50, 75, 100, 125, 150, 175],\n",
    "    \"subsample\":[0.25, 0.4, 0.5, 0.6, 0.75, 1.0],\n",
    "    \"min_samples_split\":[2, 4, 6, 8, 10, 12],\n",
    "    \"min_samples_leaf\":[1, 2, 3,4, 5,6],   \n",
    "}\n",
    "tuning_results = model.tune_hyperparameters(X_heart, y_heart, param_grid, cv=3)\n",
    "print(tuning_results['best_params'])\n",
    "print(tuning_results['best_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Metrics===\n",
      "{'accuracy': 0.7868852459016393, 'precision': 0.7352941176470589, 'recall': 0.8620689655172413, 'f1': 0.7936507936507936, 'roc_auc': 0.8459051724137931}\n",
      "===Cross Val===\n",
      "{'accuracy': {'mean': np.float64(0.8110928961748634), 'std': np.float64(0.05683811425746767)}, 'precision': {'mean': np.float64(0.8044289044289045), 'std': np.float64(0.05482653147641297)}, 'recall': {'mean': np.float64(0.866098484848485), 'std': np.float64(0.05238925308098828)}, 'f1': {'mean': np.float64(0.8334242086415999), 'std': np.float64(0.04755082348585735)}, 'roc_auc': {'mean': np.float64(0.892242364117364), 'std': np.float64(0.044243684238676334)}}\n",
      "===Feature Importance===\n",
      "          Importance\n",
      "cp          0.271179\n",
      "thal        0.152293\n",
      "oldpeak     0.132348\n",
      "ca          0.103459\n",
      "age         0.072785\n",
      "thalach     0.065468\n",
      "trestbps    0.055822\n",
      "chol        0.053773\n",
      "sex         0.038690\n",
      "slope       0.023003\n",
      "restecg     0.022784\n",
      "exang       0.007975\n",
      "fbs         0.000420\n"
     ]
    }
   ],
   "source": [
    "hyper_param_tuned_model = GradientBoostingModel(max_depth=15, learning_rate=0.01, n_estimators=50, subsample=.25, min_samples_split=6,min_samples_leaf=6, random_state=42, use_scaler=True)\n",
    "hyper_param_tuned_model = hyper_param_tuned_model.fit(X_train, y_train)\n",
    "\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "print(\"====Metrics===\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"===Cross Val===\")\n",
    "cv_results = model.cross_validate(X_heart, y_heart)\n",
    "print(cv_results)\n",
    "\n",
    "print(\"===Feature Importance===\")\n",
    "feature_importance = model.get_feature_importance(plot=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dedup X: 0\n",
      "Before dedup y: 796\n",
      "After dedup X: 0\n",
      "After dedup y: 796\n",
      "Check for NA \n",
      " 0\n",
      "Class balance: \n",
      " target\n",
      "1    164\n",
      "0    138\n",
      "Name: count, dtype: int64\n",
      "Dimensionality X:  (801, 5479)\n",
      "Dimensionality y:  (801,)\n",
      "X features:  5479\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train/evaluate on cancer dataset (multi-class)\n",
    "cancer_model = GradientBoostingModel(\n",
    "    task='classification',\n",
    "    max_depth= 3,\n",
    "    learning_rate= 0.1,\n",
    "    n_estimators= 50,\n",
    "    subsample= 1,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    multiclass=True,\n",
    "    random_state=42,\n",
    "    use_scaler=True,\n",
    ")\n",
    "print('Before dedup X:', X_cancer.duplicated().sum())\n",
    "print('Before dedup y:', y_cancer.duplicated().sum())\n",
    "#TODO ask about deduplicating \n",
    "duplicated = X_cancer.duplicated()\n",
    "X_cancer = X_cancer[~duplicated]\n",
    "y_cancer = y_cancer[~duplicated]\n",
    "print('After dedup X:', X_cancer.duplicated().sum())\n",
    "print('After dedup y:', y_cancer.duplicated().sum())\n",
    "\n",
    "\n",
    "print('Check for NA \\n', X_cancer.isna().sum().sum())\n",
    "\n",
    "print('Class balance: \\n', y_heart.value_counts())\n",
    "print('Dimensionality X: ', X_cancer.shape)\n",
    "print('Dimensionality y: ', y_cancer.shape)\n",
    "print('X features: ', len(X_cancer.columns))\n",
    "\n",
    "X_cancer.describe()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_cancer = encoder.fit_transform(y_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Metrics===\n",
      "{'accuracy': 0.9937888198757764, 'precision': 0.9967741935483871, 'recall': 0.993103448275862, 'f1': 0.9948652118100128, 'roc_auc': 0.9999149665107833}\n",
      "===Cross Val===\n",
      "{'accuracy': {'mean': np.float64(0.986273291925466), 'std': np.float64(0.006104854691187139)}, 'precision_macro': {'mean': np.float64(0.991531772226752), 'std': np.float64(0.00326352479973478)}, 'recall_macro': {'mean': np.float64(0.9833128078817734), 'std': np.float64(0.008229881945071774)}, 'f1_macro': {'mean': np.float64(0.9870345257966233), 'std': np.float64(0.005876334713557647)}, 'roc_auc_ovr': {'mean': np.float64(0.9998028291878669), 'std': np.float64(0.0002334600515504683)}}\n"
     ]
    }
   ],
   "source": [
    "#Training and eval logic for cancer model ()\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = cancer_model.train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)\n",
    "cancer_model = cancer_model.fit(X_train_cancer, y_train_cancer)\n",
    "\n",
    "print(\"===Metrics===\")\n",
    "cancer_metrics = cancer_model.evaluate(X_test_cancer, y_test_cancer)\n",
    "print(cancer_metrics)\n",
    "\n",
    "print(\"===Cross Val===\")\n",
    "cancer_cross_val = cancer_model.cross_validate(X_cancer, y_cancer)\n",
    "print(cancer_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning (Cancer)\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, 15],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [50, 75, 100, 125],\n",
    "    \"subsample\":[0.25, 0.5, 0.75, 1.0],\n",
    "    \"min_samples_split\":[2, 4, 6, 8],\n",
    "    \"min_samples_leaf\":[1,2, 4 ,6]\n",
    "}\n",
    "tuning_results = model.tune_hyperparameters(X_cancer, y_cancer, param_grid, cv=3, scoring='roc_auc_ovr')\n",
    "print(tuning_results['best_params'])\n",
    "print(tuning_results['best_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hw2 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
